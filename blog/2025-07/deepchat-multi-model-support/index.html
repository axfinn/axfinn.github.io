<!DOCTYPE html>
<html lang="zn-Hans">
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1">
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no, maximum-scale=1" />
  <meta name="author" content="jaxiu He">
  <meta name="description" content="DeepChat 多模型支持机制详解
引言
在 AI 领域，不同的大语言模型（LLM）都有各自的优势和适用场景。DeepChat 的核心价值之一就是能够统一管理和使用各种不同的 AI 模型，包括云端模型和本地模型。本文将深入分析 DeepChat 的多模型支持机制，探讨其如何实现对众多 AI 模型提供商的统一管理。
统一接口设计与实现
抽象层设计
DeepChat 采用了适配器模式来实现对不同模型提供商的支持。其核心思想是定义一个统一的接口，然后为每个模型提供商实现相应的适配器。
┌─────────────────────────────────────────────────────────────┐
│                    统一接口架构                             │
├─────────────────────────────────────────────────────────────┤
│                    ┌──────────────┐                         │
│                    │  统一接口     │                         │
│                    │ (API抽象层)   │                         │
│                    └──────────────┘                         │
│                            │                                │
│          ┌─────────────────┼─────────────────┐              │
│          │                 │                 │              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │
│  │ OpenAI 适配器 │  │ Gemini 适配器 │  │ Ollama 适配器 │       │
│  └──────────────┘  └──────────────┘  └──────────────┘       │
│          │                 │                 │              │
│    ┌─────▼─────┐    ┌─────▼─────┐     ┌─────▼─────┐         │
│    │ OpenAI API│    │Gemini API │     │ Ollama API│         │
│    └───────────┘    └───────────┘     └───────────┘         │
└─────────────────────────────────────────────────────────────┘
核心接口定义
DeepChat 定义了统一的模型接口，所有模型适配器都需要实现这些接口：">
  
  <meta property="og:url" content="https://axfinn.github.io/blog/2025-07/deepchat-multi-model-support/">
  <meta property="og:site_name" content="jaxiu He">
  <meta property="og:title" content="DeepChat 多模型支持机制详解">
  <meta property="og:description" content="DeepChat 多模型支持机制详解 引言 在 AI 领域，不同的大语言模型（LLM）都有各自的优势和适用场景。DeepChat 的核心价值之一就是能够统一管理和使用各种不同的 AI 模型，包括云端模型和本地模型。本文将深入分析 DeepChat 的多模型支持机制，探讨其如何实现对众多 AI 模型提供商的统一管理。
统一接口设计与实现 抽象层设计 DeepChat 采用了适配器模式来实现对不同模型提供商的支持。其核心思想是定义一个统一的接口，然后为每个模型提供商实现相应的适配器。
┌─────────────────────────────────────────────────────────────┐ │ 统一接口架构 │ ├─────────────────────────────────────────────────────────────┤ │ ┌──────────────┐ │ │ │ 统一接口 │ │ │ │ (API抽象层) │ │ │ └──────────────┘ │ │ │ │ │ ┌─────────────────┼─────────────────┐ │ │ │ │ │ │ │ ┌──────────────┐ ┌──────────────┐ ┌──────────────┐ │ │ │ OpenAI 适配器 │ │ Gemini 适配器 │ │ Ollama 适配器 │ │ │ └──────────────┘ └──────────────┘ └──────────────┘ │ │ │ │ │ │ │ ┌─────▼─────┐ ┌─────▼─────┐ ┌─────▼─────┐ │ │ │ OpenAI API│ │Gemini API │ │ Ollama API│ │ │ └───────────┘ └───────────┘ └───────────┘ │ └─────────────────────────────────────────────────────────────┘ 核心接口定义 DeepChat 定义了统一的模型接口，所有模型适配器都需要实现这些接口：">
  <meta property="og:locale" content="zn_Hans">
  <meta property="og:type" content="article">
    <meta property="article:section" content="blog">
    <meta property="article:published_time" content="2025-07-31T19:00:00+08:00">
    <meta property="article:modified_time" content="2025-07-31T19:00:00+08:00">
    <meta property="article:tag" content="DeepChat">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="多模型">
    <meta property="article:tag" content="API集成">
    <meta property="article:tag" content="架构设计">


  <title>
  
       DeepChat 多模型支持机制详解 | jaxiu He 
  
  </title>

  <link rel="canonical" href="https://axfinn.github.io/blog/2025-07/deepchat-multi-model-support/">

  
  

  
  <link href="https://axfinn.github.io/css/vendors-extensions/fontawesome/all.min.css" rel="stylesheet">

  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700|Ubuntu+Mono:400,400i,700,700i|Raleway:300,400,500,600">
  <link href="https://axfinn.github.io/css/font.css" rel="stylesheet"> 
    
  
  <link href="https://axfinn.github.io/css/vendors/bootstrap4/bootstrap.min.css" rel="stylesheet">
  <link href="https://axfinn.github.io/css/vendors-extensions/mdb/mdb.min.css" rel="stylesheet"> 
  <link href="https://axfinn.github.io/css/vendors/mdb/style.min.css" rel="stylesheet"> 
  <link href="https://axfinn.github.io/css/main.css" rel="stylesheet">


  
  <link rel="shortcut icon"
  
      href="https://axfinn.github.io/img/logo.png"
  
  >


  
  

  <style type="text/css">
      @media (min-width: 800px) and (max-width: 850px) {
              .navbar:not(.top-nav-collapse) {
                  background: #1C2331!important;
              }
          }
  </style>


  
    
    <link rel="stylesheet" href="https://axfinn.github.io/js/vendors/katex/katex.min.css">
  
  

  
    
    <link rel="stylesheet" href="https://axfinn.github.io/css/vendors/highlight/github-gist.css">
  

  
  
  <script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
    mermaid.initialize({ startOnLoad: true });
  </script>
  
  

  
  <script src="https://axfinn.github.io/js/dynamic-bg.js"></script>
  <link href="https://axfinn.github.io/css/dynamic-bg-control.css" rel="stylesheet">

</head>

  <body class="bg-light" data-spy="scroll" data-target="#page-scrollspy" data-offset="90">
  
    
    

    
      


<nav class="navbar fixed-top navbar-expand-lg navbar-dark scrolling-navbar">
    <div class="container">

      
      <a class="navbar-brand" href="https://axfinn.github.io/">
          
        <img class="avatar" src="https://axfinn.github.io/img/logo.png" style="width: 40px!important;height: auto;"  class="d-inline-block align-top" alt="" >
        
        <strong> jaxiu He</strong>
      </a>

      
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent"
        aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>

      
      <div class="collapse navbar-collapse" id="navbarSupportedContent">

        
        <ul class="navbar-nav mr-auto ">
          <li class="nav-item ">
            <a class="nav-link" href="https://axfinn.github.io/">Home</a>
          </li>
             
            <li class="nav-item ">
              <a class="nav-link" href="https://axfinn.github.io/blog/" >博客  </a>
            </li>
          
             
            <li class="nav-item ">
              <a class="nav-link" href="https://axfinn.github.io/moment/" >动态  </a>
            </li>
          
             
            <li class="nav-item ">
              <a class="nav-link" href="https://axfinn.github.io/about/" >关于  </a>
            </li>
          
          
        </ul>

        
        <ul class="navbar-nav nav-flex-icons">
          <li class="nav-item">
            <form class="form-inline my-2 my-lg-0">
              <input class="form-control mr-sm-2" type="search" placeholder="Search" aria-label="Search" id="search-query">
              <div class="dropdown-wrapper">
                <ul id="search-results" class="dropdown-menu"></ul>
              </div>
            </form>
          </li>
        </ul>

      </div>

    </div>
  </nav>
  
  <script src="https://axfinn.github.io/js/search.js"></script>
 
      
 






<div id="site-header" class="carousel slide carousel-fade" data-ride="carousel" style="height: 18rem;" >  

  
  
  

  
  <div class="carousel-inner" role="listbox">
    
      

        
        <div class="carousel-item active">
          <div class="view" style="background-image: url('https://axfinn.github.io/img/header-slides/raw_1515691746.jpg'); background-repeat: no-repeat; background-size: cover;">

            
            <div class="mask rgba-black-light d-flex justify-content-center align-items-center">

              
              
              

            </div>
            

          </div>
        </div>
        
      
    
      

        
        <div class="carousel-item">
          <div class="view" style="background-image: url('https://axfinn.github.io/img/header-slides//raw_1515847341.jpg'); background-repeat: no-repeat; background-size: cover;">

            
            <div class="mask rgba-black-light d-flex justify-content-center align-items-center">

            

            </div>
            

          </div>
        </div>
        
      
    

  
  </div>
  

  
  <div class="carousel-content text-center white-text wow fadeIn">
    <div class="row mx-0 headfont mt-3 pt-4">
      
      <div class="col-12 col-sm-5 align-middle">
        <a href="https://axfinn.github.io/">
          
            <img class="pull-right avatar avatar-md" src="https://axfinn.github.io/img/logo.png" alt="" >
          
        </a>
      </div>
      
      <div class="col-12 col-sm-7 text-left pl-2">
        <a href="https://axfinn.github.io/">
          <h1 class="mb-2 h1" style="font-weight: 300;" >
            <strong>jaxiu He</strong>
          </h1>
        </a>
        

             
        <div class="mt-2" style="font-size: 1rem; color: white;">
            
              <a href="//github.com/axfinn" target="_blank" rel="noopener"><i class="fab fa-github pr-1" aria-hidden="true"></i></a>    
            
            

            

            

            

            
    
            
    
        
            
                <a href="mailto:521very@email.com"><i class="far fa-envelope-open pr-1" aria-hidden="true"></i></a>
            
    
            

            
        </div>
      </div>
    </div>
  </div>
  

  
  
  

</div>
  
    

    
  
  <main class="post-main-wrapper">
    
    
    <div class="row">

      

      
      <div class="container pr-5">
      

        
        <div class="z-depth-1  post-wrapper white-bg single-post">

          <div class="post-header text-center" >
  <ul class="post-meta li-x">
    
      
        <li><a href="https://axfinn.github.io/categories/%E6%8A%80%E6%9C%AF"><i class="fas fa-folder-open pr-1" aria-hidden="true"></i> 技术 </a></li>
      
        <li><a href="https://axfinn.github.io/categories/ai%E5%B7%A5%E5%85%B7"><i class="fas fa-folder-open pr-1" aria-hidden="true"></i> AI工具 </a></li>
      
    
    
  </ul>

  <div class="px-4 post-heading">DeepChat 多模型支持机制详解</div>

  <ul class="post-meta li-x mt-1">
    
      <li>Jul 31, 2025</li>
    

    
      <li class="middot"></li>
      <li>5 minutes read</li>
    
  </ul>
  

</div>


          <div class="post-content markdown">
            <h1 id="deepchat-多模型支持机制详解">DeepChat 多模型支持机制详解</h1>
<h2 id="引言">引言</h2>
<p>在 AI 领域，不同的大语言模型（LLM）都有各自的优势和适用场景。DeepChat 的核心价值之一就是能够统一管理和使用各种不同的 AI 模型，包括云端模型和本地模型。本文将深入分析 DeepChat 的多模型支持机制，探讨其如何实现对众多 AI 模型提供商的统一管理。</p>
<h2 id="统一接口设计与实现">统一接口设计与实现</h2>
<h3 id="抽象层设计">抽象层设计</h3>
<p>DeepChat 采用了适配器模式来实现对不同模型提供商的支持。其核心思想是定义一个统一的接口，然后为每个模型提供商实现相应的适配器。</p>
<pre tabindex="0"><code>┌─────────────────────────────────────────────────────────────┐
│                    统一接口架构                             │
├─────────────────────────────────────────────────────────────┤
│                    ┌──────────────┐                         │
│                    │  统一接口     │                         │
│                    │ (API抽象层)   │                         │
│                    └──────────────┘                         │
│                            │                                │
│          ┌─────────────────┼─────────────────┐              │
│          │                 │                 │              │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐       │
│  │ OpenAI 适配器 │  │ Gemini 适配器 │  │ Ollama 适配器 │       │
│  └──────────────┘  └──────────────┘  └──────────────┘       │
│          │                 │                 │              │
│    ┌─────▼─────┐    ┌─────▼─────┐     ┌─────▼─────┐         │
│    │ OpenAI API│    │Gemini API │     │ Ollama API│         │
│    └───────────┘    └───────────┘     └───────────┘         │
└─────────────────────────────────────────────────────────────┘
</code></pre><h3 id="核心接口定义">核心接口定义</h3>
<p>DeepChat 定义了统一的模型接口，所有模型适配器都需要实现这些接口：</p>
<p>``typescript
interface ModelProvider {
// 发送聊天消息
sendMessage(messages: Message[], options: SendOptions): Promise<Response>;</p>
<p>// 流式发送聊天消息
streamMessage(messages: Message[], options: SendOptions): AsyncGenerator<string>;</p>
<p>// 获取模型列表
listModels(): Promise&lt;Model[]&gt;;</p>
<p>// 验证配置
validateConfig(config: ProviderConfig): Promise<boolean>;
}</p>
<pre tabindex="0"><code>
这种设计使得 DeepChat 可以以统一的方式处理各种不同的模型提供商，而不需要关心底层的具体实现。

## 不同 AI 服务商的适配器模式

### OpenAI 兼容适配器

由于 OpenAI API 已经成为事实标准，许多模型提供商都提供了兼容 OpenAI API 的接口。DeepChat 利用这一点，为所有兼容 OpenAI API 的模型提供商创建了一个通用适配器：

``typescript
class OpenAICompatibleProvider implements ModelProvider {
  private client: OpenAIApi;
  
  constructor(config: OpenAIConfig) {
    this.client = new OpenAIApi({
      baseURL: config.baseURL,
      apiKey: config.apiKey,
    });
  }
  
  async sendMessage(messages: Message[], options: SendOptions) {
    const response = await this.client.chat.completions.create({
      model: options.model,
      messages: messages.map(m =&gt; ({
        role: m.role,
        content: m.content,
      })),
      // 其他选项...
    });
    
    return response.choices[0].message;
  }
  
  // 其他方法实现...
}
</code></pre><p>这种方法使得 DeepChat 可以轻松支持以下模型提供商：</p>
<ul>
<li>OpenAI</li>
<li>DeepSeek</li>
<li>SiliconFlow</li>
<li>Moonshot</li>
<li>Azure OpenAI</li>
<li>以及任何兼容 OpenAI API 的服务</li>
</ul>
<h3 id="专有-api-适配器">专有 API 适配器</h3>
<p>对于一些有专有 API 的模型提供商，DeepChat 实现了专门的适配器。例如，Gemini 的适配器：</p>
<p>``typescript
class GeminiProvider implements ModelProvider {
private client: GoogleGenerativeAI;</p>
<p>constructor(config: GeminiConfig) {
this.client = new GoogleGenerativeAI(config.apiKey);
}</p>
<p>async sendMessage(messages: Message[], options: SendOptions) {
const model = this.client.getGenerativeModel({ model: options.model });</p>
<pre><code>const chat = model.startChat({
  history: messages.slice(0, -1).map(m =&gt; ({
    role: m.role === 'user' ? 'user' : 'model',
    parts: [{ text: m.content }],
  })),
});

const result = await chat.sendMessage(messages[messages.length - 1].content);
return result.response.text();
</code></pre>
<p>}
}</p>
<pre tabindex="0"><code>
## 本地模型（Ollama）集成方案

### Ollama 集成架构

Ollama 是一个流行的本地模型运行工具，DeepChat 通过直接与 Ollama API 交互来集成本地模型：
</code></pre><p>┌─────────────────┐    HTTP    ┌─────────────────┐    IPC    ┌─────────────────┐
│   DeepChat UI   │◄──────────►│  DeepChat 主进程  │◄─────────►│    Ollama 服务   │
└─────────────────┘  (Renderer) └─────────────────┘  (Main)   └─────────────────┘
│
▼
┌─────────────────┐
│  本地模型文件    │
└─────────────────┘</p>
<pre tabindex="0"><code>
### Ollama 适配器实现

DeepChat 的 Ollama 适配器不仅支持基本的聊天功能，还提供了模型管理功能：

``typescript
class OllamaProvider implements ModelProvider {
  private client: Ollama;
  private host: string;
  
  constructor(config: OllamaConfig) {
    this.host = config.host || &#39;http://localhost:11434&#39;;
    this.client = new Ollama({ host: this.host });
  }
  
  async listModels(): Promise&lt;Model[]&gt; {
    const response = await this.client.list();
    return response.models.map(model =&gt; ({
      id: model.name,
      name: model.name,
      provider: &#39;ollama&#39;,
      // 其他模型信息...
    }));
  }
  
  async pullModel(modelName: string): Promise&lt;void&gt; {
    // 下载模型
    await this.client.pull({ model: modelName });
  }
  
  async sendMessage(messages: Message[], options: SendOptions) {
    const response = await this.client.chat({
      model: options.model,
      messages: messages,
    });
    
    return response.message;
  }
}
</code></pre><h3 id="模型管理功能">模型管理功能</h3>
<p>DeepChat 还提供了图形化界面来管理 Ollama 模型：</p>
<ol>
<li><strong>模型浏览</strong> - 显示本地可用的模型列表</li>
<li><strong>模型下载</strong> - 从 Ollama 库下载新模型</li>
<li><strong>模型删除</strong> - 删除本地不需要的模型</li>
<li><strong>模型信息</strong> - 显示模型的详细信息</li>
</ol>
<h2 id="配置管理与切换">配置管理与切换</h2>
<h3 id="统一配置系统">统一配置系统</h3>
<p>DeepChat 实现了一个统一的配置系统来管理不同模型提供商的配置信息：</p>
<p>``typescript
interface ProviderConfig {
id: string;           // 唯一标识符
name: string;         // 显示名称
type: string;         // 提供商类型 (openai, gemini, ollama等)
config: any;          // 具体配置信息
enabled: boolean;     // 是否启用
}</p>
<p>class ConfigManager {
private providers: Map&lt;string, ProviderConfig&gt; = new Map();</p>
<p>addProvider(config: ProviderConfig) {
this.providers.set(config.id, config);
}</p>
<p>getProvider(id: string): ProviderConfig | undefined {
return this.providers.get(id);
}</p>
<p>listProviders(): ProviderConfig[] {
return Array.from(this.providers.values());
}
}</p>
<pre tabindex="0"><code>
### 运行时切换

用户可以在不重启应用的情况下切换不同的模型提供商和模型：

``typescript
class ModelManager {
  private currentProvider: ModelProvider | null = null;
  private providers: Map&lt;string, ModelProvider&gt; = new Map();
  
  async switchProvider(providerId: string, modelId: string) {
    // 获取配置
    const config = this.configManager.getProvider(providerId);
    if (!config) {
      throw new Error(`Provider ${providerId} not found`);
    }
    
    // 创建适配器实例
    const provider = this.createProvider(config);
    this.providers.set(providerId, provider);
    this.currentProvider = provider;
    
    // 设置当前模型
    this.currentModel = modelId;
  }
}
</code></pre><h2 id="错误处理与重试机制">错误处理与重试机制</h2>
<h3 id="统一错误处理">统一错误处理</h3>
<p>DeepChat 实现了统一的错误处理机制来处理不同模型提供商的错误：</p>
<p>``typescript
class ModelError extends Error {
constructor(
message: string,
public code: string,
public provider: string,
public details?: any
) {
super(message);
this.name = &lsquo;ModelError&rsquo;;
}
}</p>
<p>// 在适配器中处理错误
async sendMessage(messages: Message[], options: SendOptions) {
try {
// 发送消息
const response = await this.client.chat.completions.create(&hellip;);
return response;
} catch (error: any) {
// 转换为统一的错误格式
throw new ModelError(
error.message,
error.code || &lsquo;UNKNOWN_ERROR&rsquo;,
&lsquo;openai&rsquo;,
error
);
}
}</p>
<pre tabindex="0"><code>
### 重试机制

为了提高稳定性，DeepChat 实现了重试机制：

``typescript
async function withRetry&lt;T&gt;(
  operation: () =&gt; Promise&lt;T&gt;,
  maxRetries: number = 3,
  delay: number = 1000
): Promise&lt;T&gt; {
  let lastError: Error;
  
  for (let i = 0; i &lt;= maxRetries; i++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error;
      if (i &lt; maxRetries) {
        await new Promise(resolve =&gt; setTimeout(resolve, delay * Math.pow(2, i)));
      }
    }
  }
  
  throw lastError;
}
</code></pre><h2 id="小结">小结</h2>
<p>DeepChat 的多模型支持机制通过适配器模式实现了对各种 AI 模型提供商的统一管理。其核心优势包括：</p>
<ol>
<li><strong>统一接口</strong> - 通过抽象层设计，为所有模型提供商提供统一的接口</li>
<li><strong>灵活扩展</strong> - 可以轻松添加新的模型提供商支持</li>
<li><strong>本地集成</strong> - 深度集成 Ollama，提供本地模型管理功能</li>
<li><strong>配置管理</strong> - 实现了统一的配置系统，支持运行时切换</li>
<li><strong>错误处理</strong> - 提供统一的错误处理和重试机制</li>
</ol>
<p>在下一篇文章中，我们将深入探讨 DeepChat 的 MCP（Model Context Protocol）支持，分析其如何实现工具调用和资源管理功能.</p>

          </div>

          
          <div class="row">
            <div class="col-md-8">
            
              <div class="mb-5">
                
<div class="li-x div-x post-meta">
  <li class="pr-0"><a href="https://axfinn.github.io/tags/"><i class="fas fa-tags"></i></a></li>
  <div class="tags-sm">
    
      <li><a href="https://axfinn.github.io/tags/deepchat" role="button">DeepChat </a></li>
      
    
      <li><a href="https://axfinn.github.io/tags/ai" role="button">AI </a></li>
      
    
      <li><a href="https://axfinn.github.io/tags/%E5%A4%9A%E6%A8%A1%E5%9E%8B" role="button">多模型 </a></li>
      
    
      <li><a href="https://axfinn.github.io/tags/api%E9%9B%86%E6%88%90" role="button">API集成 </a></li>
      
    
      <li><a href="https://axfinn.github.io/tags/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1" role="button">架构设计 </a></li>
      
    
  </div>
</div>
              </div>
            
            </div>
            
          </div>
          

          
          <div class="row pt-3">
            <div class="col-md-6">
              
                <a href=https://axfinn.github.io/blog/2025-07/deepchat-architecture-design/ class="post-meta">Previous
                  <div class="pt-2 pb-5 d-flex">
                    <i class="fas fa-angle-left text-grey font-weight-bold mr-2 active-color"></i>
                    <span>DeepChat 架构设计解析：Electron 多平台实现原理</span>
                  </div>
                </a>
              
            </div>
            
            <div class="col-md-6 text-right" >
              
                <a href=https://axfinn.github.io/blog/2025-07/deepchat-mcp-support/ class="post-meta">Next
                  <div class="pt-2 pb-5 flex-reverse">
                    <i class="fas fa-angle-right text-grey font-weight-bold ml-2 active-color"></i>
                    <span>DeepChat MCP 支持深度剖析</span>
                  </div>
                </a>
              
            </div>
          </div>

          

        </div>
        

      </div>
      

      

    </div>
    


  </main>
  


    
    

<footer class="page-footer text-center font-small mt-4 wow fadeIn">


  
  <div class="pb-2 mt-5 pt-5">
    
      <a href="//github.com/axfinn " target="_blank" rel="noopener"><i class="fab fa-github mr-3" aria-hidden="true"></i></a>    
    
    

    

    

    

    

    


    
        <a href="mailto:521very@email.com"><i class="far fa-envelope-open mr-3" aria-hidden="true"></i></a>
    

    

    

  </div>
  

  
  <div class="copyright py-4">
    
    <span>  2016 - 2025 &copy; | Powered by Hugo and <a href='https://github.com/axfinn/AllinOne' target="_blank">AllinOne Theme</a>.  </span>
  </div>
  

  <div id="blog-pet">
    <div id="pet-toggle-button">X</div>
    <svg viewBox="0 0 100 100" xmlns="http://www.w3.org/2000/svg">
        
        <circle cx="50" cy="60" r="35" fill="#FFDDC1"/>
        
        <path d="M30 30 Q35 10 45 30 Z" fill="#FFDDC1"/>
        
        <path d="M70 30 Q65 10 55 30 Z" fill="#FFDDC1"/>
        
        <circle cx="40" cy="50" r="5" fill="#333"/>
        <circle cx="60" cy="50" r="5" fill="#333"/>
        
        <path d="M45 70 Q50 75 55 70" stroke="#333" stroke-width="2" fill="none"/>
    </svg>
    <div id="pet-speech-bubble"></div>
</div>

</footer>


    






<script type="text/javascript" src="https://axfinn.github.io/js/vendors/jquery/jquery-3.3.1.min.js"></script>
<script type="text/javascript" src="https://axfinn.github.io/js/vendors/jquery/jquery.smooth-scroll.min.js"></script>



<script type="text/javascript" src="https://axfinn.github.io/js/vendors/popper.min.js"></script>
<script type="text/javascript" src="https://axfinn.github.io/js/vendors/holder.min.js"></script>
<script type="text/javascript" src="https://axfinn.github.io/js/vendors-extensions/bootstrap4/bootstrap.js" ></script>

<script type="text/javascript" src="https://axfinn.github.io/js/vendors/mdb/mdb.min.js"></script>

<script type="text/javascript" src="https://axfinn.github.io/js/main.js"></script>



  
  <script src="https://axfinn.github.io/js/vendors/highlight.pack.js"> </script>
  <script>hljs.initHighlightingOnLoad();</script>




 
  <script src="https://axfinn.github.io/js/vendors/katex/katex.min.js"> </script>
  <script src="https://axfinn.github.io/js/vendors/katex/contrib/auto-render.min.js"></script>

  <script>
      document.addEventListener("DOMContentLoaded", function () {
          renderMathInElement(document.body);
      });
  </script>








<script type="text/javascript">
  
  new WOW().init();
</script>

<script type="text/javascript" src="https://axfinn.github.io/js/pet.js"></script>




  </body>
</html>